{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "868d1f30-19db-49ad-8ed0-f4945cdd147a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.embeddings import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5eb89e93-7226-458c-b37d-2d721716e4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load PDF file from data path\n",
    "loader = DirectoryLoader('Data/Llama2-Data',\n",
    "                         glob=\"*.pdf\",\n",
    "                         loader_cls=PyPDFLoader)\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6eac22d4-b982-4008-8bf8-34c0fd44c671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split text from PDF into chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500,\n",
    "                                               chunk_overlap=50)\n",
    "texts = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fdfd1426-4624-4ca0-934d-4c31e25de237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load embeddings model\n",
    "embeddings = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2',\n",
    "                                   model_kwargs={'device': 'cpu'})\n",
    "\n",
    "# Build and persist FAISS vector store\n",
    "vectorstore = FAISS.from_documents(texts, embeddings)\n",
    "vectorstore.save_local('vectorstore/db_faiss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58aa145e-f159-48a1-b3fe-f8985d17f773",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_template = \"\"\"Use the following pieces of information to answer the user's question.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "Only return the helpful answer below and nothing else.\n",
    "Helpful answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a2c2792-18e0-4633-a2eb-8ee339b89dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import CTransformers\n",
    "\n",
    "# Location of downloaded GGML model\n",
    "model_location = 'models/models--TheBloke--Llama-2-7B-Chat-GGML/snapshots/76cd63c351ae389e1d4b91cab2cf470aab11864b/llama-2-7b-chat.ggmlv3.q4_0.bin'\n",
    "# Local CTransformers wrapper for Llama-2-7B-Chat\n",
    "llm = CTransformers(model=model_location,\n",
    "                    model_type='llama', # Model type Llama\n",
    "                    config={'max_new_tokens': 256,\n",
    "                            'temperature': 0.01})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7c8e8d5-12eb-461d-acdf-5d3e3dd6fbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "# Wrap prompt template in a PromptTemplate object\n",
    "def set_qa_prompt():\n",
    "    prompt = PromptTemplate(template=qa_template,\n",
    "                            input_variables=['context', 'question'])\n",
    "    return prompt\n",
    "\n",
    "\n",
    "# Build RetrievalQA object\n",
    "def build_retrieval_qa(llm, prompt, vectordb):\n",
    "    dbqa = RetrievalQA.from_chain_type(llm=llm,\n",
    "                                       chain_type='stuff',\n",
    "                                       retriever=vectordb.as_retriever(search_kwargs={'k':2}),\n",
    "                                       return_source_documents=True,\n",
    "                                       chain_type_kwargs={'prompt': prompt})\n",
    "    return dbqa\n",
    "\n",
    "\n",
    "# Instantiate QA object\n",
    "def setup_dbqa():\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "                                       model_kwargs={'device': 'cpu'})\n",
    "    vectordb = FAISS.load_local('vectorstore/db_faiss', embeddings)\n",
    "    qa_prompt = set_qa_prompt()\n",
    "    dbqa = build_retrieval_qa(llm, qa_prompt, vectordb)\n",
    "\n",
    "    return dbqa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69b11cd0-c3d4-44f6-bf97-c697c6f9ef73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer: The minimum guarantee payable by adidas over the term of the agreement is £750 million, subject to certain adjustments.\n",
      "==================================================\n",
      "\n",
      "Source Document 1\n",
      "\n",
      "Source Text: The minimum guarantee payable by adidas over the term of our agreement with them is equal to\n",
      "Document Name: Data\\Llama2-Data\\manu-20f-2022-09-24.pdf\n",
      "Page Number: 84\n",
      "\n",
      "==================================================\n",
      "\n",
      "Source Document 2\n",
      "\n",
      "Source Text: Pursuant to our contract with adidas, which began on 1 August 2015, the minimum guarantee payable\n",
      "by adidas over the 10-year term of the agreement is equal to £750 million, subject to certain adjustments.See “Item 4. Information on the Company—Revenue Sectors—Commercial—Retail, Merchandising,Apparel & Product Licensing” for additional information regarding our agreement with adidas.\n",
      "We also maintain a mixture of long-term debt and capacity under our revolving facilities in order to\n",
      "Document Name: Data\\Llama2-Data\\manu-20f-2022-09-24.pdf\n",
      "Page Number: 74\n",
      "\n",
      "==================================================\n",
      "Time to retrieve response: 109.0811162\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "\n",
    "start = timeit.default_timer() # Start timer\n",
    "question = \"How much is the minimum gurantee payable by adidas?\"\n",
    "\n",
    "# Setup QA object\n",
    "dbqa = setup_dbqa()\n",
    "\n",
    "# Parse input from argparse into QA object\n",
    "response = dbqa({'query': question})\n",
    "end = timeit.default_timer() # End timer\n",
    "\n",
    "# Print document QA response\n",
    "print(f'\\nAnswer: {response[\"result\"]}')\n",
    "print('='*50) # Formatting separator\n",
    "\n",
    "# Process source documents for better display\n",
    "source_docs = response['source_documents']\n",
    "for i, doc in enumerate(source_docs):\n",
    "    print(f'\\nSource Document {i+1}\\n')\n",
    "    print(f'Source Text: {doc.page_content}')\n",
    "    print(f'Document Name: {doc.metadata[\"source\"]}')\n",
    "    print(f'Page Number: {doc.metadata[\"page\"]}\\n')\n",
    "    print('='* 50) # Formatting separator\n",
    "    \n",
    "# Display time taken for CPU inference\n",
    "print(f\"Time to retrieve response: {end - start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea373ad-5b42-4ce5-bd57-0b27fb5b42cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timeit.default_timer() # Start timer\n",
    "# question = \"How much was the total revenue generated?\"\n",
    "question = \"How many Twitter followers?\"\n",
    "\n",
    "# Parse input from argparse into QA object\n",
    "response = dbqa({'query': question})\n",
    "end = timeit.default_timer() # End timer\n",
    "\n",
    "# Print document QA response\n",
    "print(f'\\nAnswer: {response[\"result\"]}')\n",
    "print('='*50) # Formatting separator\n",
    "\n",
    "# Process source documents for better display\n",
    "source_docs = response['source_documents']\n",
    "for i, doc in enumerate(source_docs):\n",
    "    print(f'\\nSource Document {i+1}\\n')\n",
    "    print(f'Source Text: {doc.page_content}')\n",
    "    print(f'Document Name: {doc.metadata[\"source\"]}')\n",
    "    print(f'Page Number: {doc.metadata[\"page\"]}\\n')\n",
    "    print('='* 50) # Formatting separator\n",
    "    \n",
    "# Display time taken for CPU inference\n",
    "print(f\"Time to retrieve response: {end - start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce7e396-e87b-4bde-8609-00ab6211c740",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
